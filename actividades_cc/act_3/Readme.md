# Actividad 3

Este repositorio ilustra un flujo de _end-to-end_ para crear, versionar y desplegar un modelo de **Random Forest** en Azure ML empleando un √∫nico **pipeline** de _scikit-learn_.  
El objetivo es mostrar c√≥mo:

1. Preprocesar y entrenar localmente.  
2. Empaquetar el preprocesador + modelo en un solo artefacto (`pipeline.pkl`).  
3. Subir y desplegar ese artefacto como un servicio web escalable en Azure ML.  
4. Validar el servicio mediante llamadas a la API.

---

## Estructura del proyecto

```
.
‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îî‚îÄ‚îÄ build_pipeline.ipynb      # Preprocesado + entrenamiento + exportaci√≥n .pkl
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ get_data.ipynb            # Extracci√≥n de datos desde Azure SQL
‚îÇ   ‚îî‚îÄ‚îÄ upload_model.ipynb        # Creaci√≥n de Workspace y despliegue
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ test_endpoint.ipynb       # Consumo de la API publicada
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

| Carpeta / archivo                  | Descripci√≥n breve |
| ---------------------------------- | ----------------- |
| **model**                          | Entrenamiento y generaci√≥n del `pipeline.pkl`, que combina el preprocesador y el clasificador `RandomForestClassifier`. Con esto evitamos registrar dos modelos independientes. |
| **notebooks/get_data.ipynb**       | Conecta a una base de datos **Azure SQL** que contiene la base de ejemplo _AdventureWorks_, extrae tablas de ventas y guarda los datos limpiados en formato Parquet/CSV. |
| **notebooks/upload_model.ipynb**   | ‚ÄúDeployer‚Äù: crea (o reutiliza) un Workspace de Azure ML, sube el `pipeline.pkl`, define el entorno de ejecuci√≥n con sus dependencias, configura la inferencia (CPU/cores, imagen base, entry script) y publica el servicio. |
| **api/test_endpoint.ipynb**        | Ejemplo de c√≥mo llamar al endpoint REST (token, cabeceras, _payload_, parseo de respuesta) para comprobar que todo funcione. |

---

## Requisitos previos

| Herramienta / servicio       | Recomendado            |
| ---------------------------- | ---------------------- |
| **Python**                   | = 3.11.9 |
| **Azure CLI**                | ‚â• 2.60 |
| **Extensi√≥n Azure ML**       | `az extension add -n ml` |
| **Bibliotecas**              | ver `requirements.txt` |
| **URI**                      | {"URI": ["URL"]}|
| **Suscripci√≥n de Azure**     | rol _Contributor_ sobre el _Resource Group_ de destino |
| **Base de datos Azure SQL**  | Acceso de lectura y cadena de conexi√≥n v√°lidos |

---

## üöÄ Pasos para reproducir

1. **Clona el repo y crea el entorno:**

   ```bash
   git clone https://github.com/tu-usuario/nombre-repo.git
   cd nombre-repo
   python -m venv .venv && source .venv/bin/activate   # Windows: .venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Obt√©n los datos** (opcional si ya los tienes):

   1. Abre `notebooks/get_data.ipynb`.  
   2. Introduce la cadena de conexi√≥n de Azure SQL.  
   3. Ejecuta el notebook; generar√° un archivo `SalesLT.csv`.

3. **Entrena y crea el pipeline:**

   1. Abre `model/Modelo.ipynb`.  
   2. Ajusta hiperpar√°metros si lo deseas (n_estimators, max_depth, etc.).  
   3. Ejecuta todo; al final tendr√°s `model/RandomForest_BestModel.pkl` listo.

4. **Despliega en Azure ML:**

   1. Abre `notebooks/upload_model.ipynb`.  
   2. Completa los valores de: suscripci√≥n, grupo de recursos, nombre de Workspace, nombre del _compute_ target, etc.  
   3. Ejecuta cada celda. El notebook:  
      - Crea/reutiliza el Workspace.  
      - Registra el artefacto `RandomForest_BestModel.pkl` como **modelo**.  
      - Define el `Environment` (versi√≥n de Python + librer√≠as).  
      - Configura la inferencia (`InferenceConfig` + `AciWebservice/AksWebservice`).  
      - Despliega y devuelve la **URL del endpoint** + **clave de acceso**.

5. **Valida el servicio:**

   1. Abre `api/test_endpoint.ipynb`.  
   2. Pega la URL y la clave.  
   3. Ejecuta; ver√°s la predicci√≥n JSON en la salida.


## Limpieza

Cuando termines, elimina los recursos para no incurrir en costos:

```bash
az ml workspace delete \
   --name $AZ_WORKSPACE_NAME \
   --resource-group $AZ_RESOURCE_GROUP \
   --yes
```



